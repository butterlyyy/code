{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f04ba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer\n",
    "#Stream of strings\n",
    "#sentence print\n",
    "#Separating doc into sentences\n",
    "# Tagger, POS, POS Count\n",
    "#Session 4:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831c41d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "doc_1=nlp('NMIMS is the all-encompassing educational platform for diverse fields of ca')\n",
    "type(doc_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f03a1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer\n",
    "for token in doc_1:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd56e60",
   "metadata": {},
   "source": [
    "Stream of strings as input\n",
    "When there is a stream of strings as input, we need to\n",
    "\n",
    "use nlp.pipe() instead of nlp()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ffaf68",
   "metadata": {},
   "source": [
    "#### List of string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cfe046",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_2=['Today is Monday','Tomorrow is Tuesday',\n",
    "       'Yesterday was a holiday']\n",
    "type(text_2)\n",
    "#sentence- as list\n",
    "for sentence in nlp.pipe(text_2):\n",
    "    print(sentence)\n",
    "# sentence- as tuple\n",
    "text_3=('Today is Monday','Tomorrow is Tuesday',\n",
    "       'Yesterday was Sundaya,a holiday')\n",
    "type(text_3)\n",
    "for sent in nlp.pipe(text_3):\n",
    "    print(sent)\n",
    "    for token in sent:\n",
    "        print(token)\n",
    "# List of tuple\n",
    "#Creating datafram- line 23, sess-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1ade45",
   "metadata": {},
   "source": [
    "###### Separating doc into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aab7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in doc_1.sents:\n",
    "    print(sent)\n",
    "#count\n",
    "sent_count=0\n",
    "for sent in doc_1.sents:\n",
    "    sent_count=sent_count+1\n",
    "    print(sent_count,'==>',sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3664243d",
   "metadata": {},
   "source": [
    "#### Tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf897036",
   "metadata": {},
   "source": [
    "The main difference between the two code snippets is that token.tag_ returns a string representation of the token's part-of-speech tag, while token.tag returns an integer code representing the tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32133da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1)\n",
    "for token in doc_1:\n",
    "    print(token.text,'==>',token.tag_)\n",
    "spacy.explain('NNS') #eg\n",
    "\n",
    "#2)\n",
    "for token in doc_1:\n",
    "    print(token.text,'==>',token.tag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad49d827",
   "metadata": {},
   "source": [
    "In summary, POS is a linguistic concept that refers to the grammatical category of a word, while a tagger is an algorithm or component of an NLP system that assigns POS tags to words using a predefined tagset and various techniques and algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85b89d4",
   "metadata": {},
   "source": [
    "#### POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64701bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 STRING)\n",
    "for token in doc_1:\n",
    "    print(token.text,'==>',token.pos_)\n",
    "#2 Number)\n",
    "for token in doc_1:\n",
    "    print(token.text,'==>',token.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8020a961",
   "metadata": {},
   "source": [
    "#### POS count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec67d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_count=doc_1.count_by(spacy.attrs.POS)\n",
    "pos_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190c1aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in sorted(pos_count.items()):\n",
    "    print(x,doc_1.vocab[x].text,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e900c153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation of POS- sess 3-last\n",
    "# Converting a text into a DF with tokens,pos- sess-3 last"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54bd85e",
   "metadata": {},
   "source": [
    "#### Session 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f8a3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "type(nlp)\n",
    "doc1=nlp('Let’s start by differentiating between data analytics and traditional')\n",
    "doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7875a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizer\n",
    "for token in doc1:\n",
    "    print(token)\n",
    "#Tagger\n",
    "for token in doc1:\n",
    "    print(token.text,token.tag_)\n",
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc1,style='dep')\n",
    "for token in doc1:\n",
    "    print(token.text,'==>',token.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16d1cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noun chunks\n",
    "for chunk in doc1.noun_chunks:\n",
    "    print(chunk.text, '==>',chunk.label_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa428725",
   "metadata": {},
   "source": [
    "#### NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235a4f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc2:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860d5f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc2.ents:\n",
    "    print(ent.text,'==>',ent.label_)\n",
    "spacy.explain('NORP') #Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90268bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of entities\n",
    "\n",
    "ent_list=[]\n",
    "for ent in doc2.ents:\n",
    "    ent_list.append(ent.label_)\n",
    "print(ent_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5123c968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tuples of text and the respective entities\n",
    "\n",
    "for ent in doc2.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "ent_list=[(ent.text,ent.label_) for ent in doc2.ents]\n",
    "print(ent_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90c40ee",
   "metadata": {},
   "source": [
    "#### NER for web data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3664e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url='https://en.wikipedia.org/wiki/India'\n",
    "print(url)\n",
    "request=requests.get(url)\n",
    "print(request)\n",
    "soup_request=BeautifulSoup(request)\n",
    "print(soup_request)\n",
    "\n",
    "text= soup_request.body.text\n",
    "print(text)\n",
    "type(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f087db45",
   "metadata": {},
   "source": [
    "Therefore, the main difference between the two code snippets is that the first one simply retrieves the text content of a response object, while the second one converts the text content into an HTML parse tree object that can be navigated and modified using the BeautifulSoup library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe0b792",
   "metadata": {},
   "source": [
    "##### Converting str to doc using nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c626a5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3=nlp(text)\n",
    "type(doc3)\n",
    "doc3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1248a84f",
   "metadata": {},
   "source": [
    "##### Tokenizer¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed3146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc3:\n",
    "    print(token.text)\n",
    "len(doc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b2d75b",
   "metadata": {},
   "source": [
    "##### List of entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b54238c",
   "metadata": {},
   "source": [
    "for ent in doc3.ents:\n",
    "    print(ent.text,'==>',ent.label_)\n",
    "ent_list=[]\n",
    "\n",
    "displacy.render(doc3, style='ent')\n",
    "\n",
    "for ent in doc3.ents:\n",
    "    ent_list.append(ent.label_)\n",
    "print(ent_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405c39f8",
   "metadata": {},
   "source": [
    "from collections import Counter\n",
    "Counter(ent_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7a2d92",
   "metadata": {},
   "source": [
    "#### Entities most appeared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ca7581",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_ent=[]\n",
    "for ent in doc3.ents:\n",
    "    most_ent.append(ent.text)\n",
    "print(most_ent)\n",
    "\n",
    "mmon\n",
    "\n",
    "Counter(most_ent).most_common()\n",
    "Counter(most_ent).most_common(10) #10 most occured NE in text\n",
    "print(len(doc3.ents))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
